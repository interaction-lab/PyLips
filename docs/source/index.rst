Welcome to PyLips's documentation!
===================================

.. image:: _static/imgs/pylips_text.png

**PyLips** is a Python-based interface for developing screen-based conversational agents.
It is designed to make developing socially assistive robotics easier by providing a
simple, expressive, and customizable framework for developing conversational agents.

.. raw:: html

    <div style="position: relative; max-width: 100%; height: auto; margin-bottom: 2em;">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/6XCySZ2VXCE?si=hZ1mUQ4JhM7Gep0V" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    </div>

PyLips is easy to install, simple to use, and open-source.
It comes ready to use with your system's speech synthesis tools, and
uses other free and open-source software for turning these sounds into facial expressions.
Check out the :doc:`usage` section for installation instructions, or fork me on
Github_.

.. _Github: https://github.com/interaction-lab/PyLips

.. image:: _static/imgs/many_faces.png

.. note::

   This project is under active development. Fill out `this survey <https://forms.gle/h9PtDMpZnvXqR9bf6>`_ to provide feedback on using PyLips! Please raise an issue on github if you are having any trouble.

Contents
--------

.. toctree::
   :maxdepth: 4

   usage
   tutorials

.. toctree::
   :maxdepth: 2
   :caption: API

   api/pylips.face
   api/pylips.speech


