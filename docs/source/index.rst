Welcome to PyLips's documentation!
===================================

.. image:: _static/imgs/pylips_text.png

**PyLips** is a Python-based interface for developing screen-based conversational agents.
It is designed to make developing socially assistive robotics easier by providing a
simple, expressive, and customizable framework for developing conversational agents.


PyLips is easy to install, simple to use, and open-source.
It comes ready to use with your system's speech synthesis tools, and
uses other free and open-source software for turning these sounds into facial expressions.
Check out the :doc:`usage` section for installation instructions, or fork me on
Github_.

.. _Github: https://github.com/interaction-lab/PyLips

.. image:: _static/imgs/many_faces.png

.. raw::
   
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/i5yTNmkXz68?si=RYQoLdVElCLriMCk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    </div>

.. note::

   This project is under active development. Please raise an issue on github if you are having any trouble!

Contents
--------

.. toctree::
   :maxdepth: 4

   usage
   tutorials

.. toctree::
   :maxdepth: 2
   :caption: API

   api/pylips.face
   api/pylips.speech


